---
title: "hw11"
author: "Your Name"
date: "2016-12-04"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Q84

##a

$$b=r \cdot \frac{S_{Weight}}{S_{Height}}=0.75 * 15 / 7=1.61$$
$$a=E(Weight) - b \cdot E(Height) = 94 - 1.61 * 46= 19.94$$

Thus $$\hat{{Weight}}=1.61 \cdot {Height}+19.94$$

##b

$$\hat {{Weight}}=1.61 \cdot {Height}+19.94=1.61*5+19.94=27.99$$

The predicted weight of a girl who is 5 ft. tall is 27.99.

##c

$$r^2=Cor(Weight,Height)^2=0.75^2=56.26$$

About 56.25% of the variability in Weight content can be explained by this least-squares line.

#Q85

##a

- The correlation coefficient of **Kills** and **Assts** is 0.97.
- scatter plot of the Kills against Assts also tell us that they are positively correlated, which means that Kills will increase with the increase of Assts.

```{r, message=FALSE, warning=FALSE}
library(ggplot2)
library(car)
x <- read.csv('C://Users//mali//Documents//Volleyball2009.csv',
              header = T)
str(x)
ggplot(data=x,aes(x=Assts,y=Kills))+geom_point()+
    geom_smooth(method = 'lm')+
    labs(title='Kills VS Assts')
cor(x$Assts,x$Kills)
```

##b

$$Kills=0.94699 \cdot Assts +1.73626 $$
$$R-squared=0.9367$$

```{r}
lm1 <- lm(Kills~Assts,data=x)
summary(lm1)

```

##c

I use **residualPlots** function in **car** package to create the residuals plot,which will tell me more information about my linear model.

The smoother added to the residuals and fitted values plot indicates slight curvature and we should  do more investigation about my linear model.But in combination with the actual situation, this error is acceptable.I think my model is OK.

```{r}
residualPlots(lm1)
```

#Q86

##a

- The correlation coefficient of **Year** and **Level** is 1.
- scatter plot of the Level against Year also tell us that they are positively correlated, which means that Level will increase with the increase of Year


```{r}
x <- read.csv('C://Users//mali//Documents//Maunaloa.csv',
              header = T)
str(x)
ggplot(data=x,aes(x=Year,y=Level))+geom_point()+
    geom_smooth(method = 'lm')+
    labs(title='Level VS Year')
cor(x$Level,x$Level)
```


##b

The equation for the least-squares equation is $$Level=1.826403 \cdot Year -3279.592814$$ 

```{r}
lm2 <- lm(Level~Year,data=x)
summary(lm2)
```

##c

The smoother added to the residuals and fitted values plot indicates Serious curvature and we must  do more investigation about my linear model.
I think  a straight line model is not appropriate.We may need to fit a linear model with adding a term square of **Year**.

```{r}
residualPlots(lm2)
```

#Q90

- The correlation between alcohol and calories is $Cor(Alcohol,Calories)=0.5371458$ .
- 95% bootstrap percentile confidence interval for the true correlation is $[0.3734308,0.7484831]$

```{r}
x <- read.csv('C://Users//mali//Documents//Alelager.csv',header = T)
str(x)
# correlation between alcohol and calories
with(x,cor(Alcohol,Calories))
cor.test(~Alcohol+Calories,data=x)

##bootstrap percentile confidence interval
N <- 1e4
cor.boot <- numeric(N)
for (i in 1:N) {
   ind <- sample(x = 1:nrow(x),size = nrow(x),replace = T)
   cor.boot[i] <-cor(x[ind,'Alcohol'],x[ind,'Calories'])
}
quantile(cor.boot,c(0.025,0.975))
```


#Chihara 9.7#14

##a

- The correlation coefficient of **Illit** and **Births** is 0.768663. There is  a relationship between female literacy and birth rate.
- scatter plot of the Births against Illit also tell us that they are positively correlated, which means that Births will increase with the increase of Illit



```{r}
x <- read.csv('C://Users//mali//Documents//Illiteracy.csv',
              header = T)
str(x)
##a
ggplot(data=x,aes(x=Illit,y=Births))+
  geom_point()+geom_smooth(method = 'lm')+
  labs(title='Births VS Illit')
cor(x$Births,x$Illit)
```


##b

- The equation for the least-squares equation is $Births=0.05452 \cdot Illit +1.94874$ .
- $r^2=0.5908$

```{r}
lm3 <- lm(Births~Illit,data=x)
summary(lm3)
```

##c

The smoother added to the residuals and fitted values plot indicates slight curvature and we should  do more investigation about my linear model.But in combination with the actual situation, this error is acceptable.I think my model is OK.

```{r}
residualPlots(lm3)
```

##d

The equation for the least-squares equation is $Births=0.05452 \cdot Illit +1.94874$.We Can say that reducing illiteracy will cause the birth rate to go down.


#Q88

##a

Scatter plot of the Y against X  tells us that they are positively correlated, which means that Y will increase with the increase of X. And there is  a relationship between Y and X.


```{r}
x <- read.csv('C://Users//mali//Documents//corrExerciseA.csv',
              header = T)
str(x)
##a
ggplot(data=x,aes(x=X,y=Y))+geom_point()+
    geom_smooth(method = 'lm')+
    labs(title='Y VS X')
```

##b

- For group A scatter plot of the Y against X  is a straight line,which means that Y and X is Independent. And there is not   a relationship between Y and X.
- For group B,scatter plot of the Y against X  tells us that they are positively correlated, which means that Y will increase with the increase of X. And there is  a relationship between Y and X.


```{r}
ggplot(data=x,aes(x=X,y=Y))+geom_point()+
  geom_smooth(method = 'lm',aes(col=Z),show.legend = F)+
  labs(title='Y VS X') +facet_grid(.~Z)
```

##c

-  For group A $r_A=0.1335408$ .And the absolute value of the correlation coefficient is very close to 0,which means that Y and X is Independent. And there is not   a relationship between Y and X.
- For group B $r_B=0.65303$.which means that Y will increase with the increase of X. And there is  a relationship between Y and X.


```{r}
#a
with(x[x$Z=='A',],cor(X,Y))
#b
with(x[x$Z=='B',],cor(X,Y))
```

##d

When fiting linear regression model, we need to pay attention to the influence of different groups. For data with some different groups, we should think about the effect of grouping on the results .

#Q89

##a

- The correlation coefficient of **Gestation** and **Weight** is 0.3486057. There is  a relationship between female Weight and Gestation.
- scatter plot of the Weight against Gestation. also tell us that they are positively correlated, which means that Weight will increase with the increase of Gestation.

```{r}
x <- read.csv('C://Users//mali//Documents//NCBirths2004.csv',header = T)
str(x)
#a
ggplot(data=x,aes(x=Gestation,y=Weight))+geom_point()+
    geom_smooth(method = 'lm')+
    labs(title='Weight VS Gestation')
with(x,cor(Weight,Gestation))
```

##b & c

- The equation for the least-squares equation is $Weight=149. \cdot Gestation -2379.69$.Weight will increase 149  with the  Gestation per increase 1 and when Gestation is 0, weight  would be -2379.69.
- $r^2=0.1215$.About 12.15% of the variability in Weight content can be explained by this least-squares line.

```{r}
#b
lm4 <- lm(Weight~Gestation,data=x)
summary(lm4)
```

##d

The smoother added to the residuals and fitted values plot indicates slight curvature and we should  do more investigation about my linear model.But in combination with the actual situation, this error is acceptable.I think my model is OK.

```{r}
residualPlots(lm4)
```

##e

$\sigma=457.367$

```{r}
summary(lm4)$sigma
```


##f

95% confidence interval for the true slope $\beta$ is $[124.2235,173.7672]$

```{r}
confint(lm4,level = 0.95)
```

#9.7#20

##a

For every additional 10 h of tutoring, the corresponding change in the test score is $10*1.45=14.5$.

##b

$r^2=Cor(Scores,Hours)^2=0.855$ and $b=cor \cdot \frac{S_{Scores}}{S_{Hours}}=1.45$ thus
$$S_{Scores}= \frac{1.45*27.5}{0.855^0.5}=43.12386$$

##c

A $1- \alpha \cdot 100\%$ confidence interval for $\beta$ is given by
$$\hat \beta \pm q \hat{SE} \hat{\beta}$$

the 0.975 quantile for the t distribution with $df=100-2=98$ degrees of freedom $q =1.98$. Thus,the 95% confidence interval for the true slope is $$[1.330042,1.569958]$$


```{r}
#ssx
ssx <- (100-1)*27.5^2
#S
S <- 16.54
#SE beat
se <- S/sqrt(ssx)
#q
q <- qt(0.975,df = 100-2)
#lower
1.45 - q*se
#upper
1.45 + q*se
```


##d


A $1- \alpha \cdot 100\%$ confidence interval for $E(Y_s)$ at $X=X_s$ is given by $$\hat{Y_s} \pm q \hat {SE} = \hat{Y_s} \pm  qS \sqrt{ \frac{1}{n}+ \frac{ (x_s - E(x)^2)}{ ss_x }}$$

the 0.975 quantile for the t distribution with $df=100-2=98$ degrees of freedom $q =1.98$. Thus,95% confidence interval for the mean score for students who are tutored 50 h is $$[571.8633,578.5367]$$


```{r}
#ssx
ssx <- (100-1)*27.5^2
#E(Y)
Y <- 502.7+1.45*50
#S
S <- 16.54
#se
se <- S*sqrt(1/100+ (50-55)^2/ssx )
#q
q <- qt(0.975,df = 100-2)
#lower
Y-q*se
# upper
Y+q*se
```

