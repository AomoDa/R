---
title: "hw11"
author: "Your Name"
date: "2016-12-04"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Q84

##a

$$b=r \cdot \frac{S_{Weight}}{S_{Height}}=0.75 * 17 / 7=1.82$$
$$a=E(Weight) - b \cdot E(Height) = 17 - 1.82 * 7= 4.26$$

Thus $$\hat{{Weight}}=1.82 \cdot {Height}+4.26$$

##b

$$\hat {{Weight}}=1.82 \ cdot {Height}+4.26=1.82*5+4.26=13.36$$

The predicted weight of a girl who is 5 ft. tall is 13.36.

##c

$$r^2=Cor(Weight,Height)^2=0.75^2=56.26$$

About 56.25% of the variability in fat content can be explained by this least-squares line.

#Q85

##a

- The correlation coefficient of **Kills** and **Assts** is 0.97.
- scatter plot of the Kills against Assts also tell us that they are positively correlated, which means that Kills will increase with the increase of Assts.

```{r, message=FALSE, warning=FALSE}
library(ggplot2)
library(car)
x <- read.csv('C://Users//AomoDa//Documents//Volleyball2009.csv',
              header = T)
str(x)
ggplot(data=x,aes(x=Assts,y=Kills))+geom_point()+
    geom_smooth(method = 'lm')+
    labs(title='Kills VS Assts')
cor(x$Assts,x$Kills)
```

##b

$$Kills=0.94699 \cdot Assts +1.73626 $$
$$R-squared=0.9367$$

```{r}
lm1 <- lm(Kills~Assts,data=x)
summary(lm1)

```

##c

I use **residualPlots** function in **car** package to create the residuals plot,which will tell me more information about my linear model.

```{r}
residualPlots(lm1)
```

#Q86

##a

```{r}
x <- read.csv('C://Users//AomoDa//Documents//Maunaloa.csv',
              header = T)
str(x)
ggplot(data=x,aes(x=Year,y=Level))+geom_point()+
    geom_smooth(method = 'lm')+
    labs(title='Level VS Year')
cor(x$Level,x$Level)
```


##b

The equation for the least-squares equation is $$Level=1.826403 \cdot Year -3279.592814$$ 

```{r}
lm2 <- lm(Level~Year,data=x)
summary(lm2)
```

##c

```{r}
residualPlots(lm2)
```

#Q90

The correlation between alcohol and calories is $Cor(Alcohol,Calories)=0.5371458$ and 95% bootstrap percentile confidence
interval for the true correlation is $[0.3734308,0.7484831]$

```{r}
x <- read.csv('C://Users//AomoDa//Documents//Alelager.csv',header = T)
str(x)
# correlation between alcohol and calories
with(x,cor(Alcohol,Calories))
cor.test(~Alcohol+Calories,data=x)

##bootstrap percentile confidence interval
N <- 1e4
cor.boot <- numeric(N)
for (i in 1:N) {
   ind <- sample(x = 1:nrow(x),size = nrow(x),replace = T)
   cor.boot[i] <-cor(x[ind,'Alcohol'],x[ind,'Calories'])
}
quantile(cor.boot,c(0.025,0.975))
```


#Chihara 9.7#14

##a


```{r}
x <- read.csv('C://Users//AomoDa//Documents//Illiteracy.csv',
              header = T)
str(x)
##a
ggplot(data=x,aes(x=Illit,y=Births))+
  geom_point()+geom_smooth(method = 'lm')+
  labs(title='Births VS Illit')
cor(x$Births,x$Illit)
```


##b

```{r}
lm3 <- lm(Births~Illit,data=x)
summary(lm3)
```

##c

```{r}
residualPlots(lm3)
```

#Q88

##a


```{r}
x <- read.csv('C://Users//AomoDa//Documents//corrExerciseA.csv',
              header = T)
str(x)
##a
ggplot(data=x,aes(x=X,y=Y))+geom_point()+
    geom_smooth(method = 'lm')+
    labs(title='Y VS X')
```

##b

```{r}
ggplot(data=x,aes(x=X,y=Y))+geom_point()+
  geom_smooth(method = 'lm',aes(col=Z),show.legend = F)+
  labs(title='Y VS X')
# +facet_grid(.~Z)
```

##c

```{r}
lm_a <- lm(Y~X,data = x,subset = Z=='A')
lm_b <- lm(Y~X,data = x,subset = Z=='B')
summary(lm_a)
summary(lm_b)

```

#Q89

##a

```{r}
x <- read.csv('C://Users//AomoDa//Documents//NCBirths2004.csv',header = T)
str(x)
#a
ggplot(data=x,aes(x=Gestation,y=Weight))+geom_point()+
    geom_smooth(method = 'lm')+
    labs(title='Weight VS Gestation')
with(x,cor(Weight,Gestation))
```

##b

```{r}
#b
lm4 <- lm(Weight~Gestation,data=x)
par(mfrow=c(2,2))
plot(lm4)
par(mfrow=c(1,1))
```

##c

```{r}
summary(lm4)
```

##d

```{r}
residualPlots(lm4)
```

##e

```{r}
summary(lm4)$sigma
```


##f

```{r}
confint(lm4,level = 0.95)
```

#9.7#20

##a

For every additional 10 h of tutoring, the corresponding change in the test score is $10*1.45=14.5$.

##b

$r^2=Cor(Scores,Hours)^2=0.855$ and $b=cor \cdot \frac{S_{Scores}}{S_{Hours}}=1.45$ thus
$$S_{Scores}= \frac{1.45*27.5}{0.855^0.5}=43.12386$$

##c

A $1- \alpha \cdot 100\%$ confidence interval for $\beta$ is given by
$$\hat \beta \pm q \hat{SE} \hat{\beta}$$

the 0.975 quantile for the t distribution with 1007 degrees of freedom $q =1.98$. Thus,the 95% confidence interval for the true slope is $$[1.449562,1.450438]$$


```{r}
#ssx
(100-1)*27.5^2
#S
16.54
#SE beat
16.54/( (100-1)*27.5^2)

#lower
1.45 - qt(0.975,df = 100-2)*16.54/( (100-1)*27.5^2)
#upper
1.45 + qt(0.975,df = 100-2)*16.54/( (100-1)*27.5^2)
```


##d


A $1- \alpha \cdot 100\%$ confidence interval for $E(Y_s)$ at $X=X_s$ is given by $$\hat{Y_s} \pm q \hat {SE} = \hat{Y_s} \pm  qS \sqrt{ \frac{1}{n}+ \frac{ (x_s - E(x)^2)}{ ss_x }}$$

the 0.975 quantile for the t distribution with 1007 degrees of freedom $q =1.98$. Thus,95% confidence interval for the mean score for students who are
tutored 50 h is $$[571.8633,578.5367]$$


```{r}
#ssx
(100-1)*27.5^2
#E(Y)
502.7+1.45*50
#q
qt(0.975,df = 100-2)
#S
16.54
#lower
502.7+1.45*50- qt(0.975,df = 100-2)*16.54*sqrt(1/100+(50-55)^2/((100-1)*27.5^2) )
# upper
502.7+1.45*50 + qt(0.975,df = 100-2)*16.54*sqrt(1/100+(50-55)^2/((100-1)*27.5^2) )
```

