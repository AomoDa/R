---
title: "hw10"
author: "Your Name"
date: "2016-11-26"
output: 
  word_document: 
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Q74

T confidence interval for the mean difference

n approximate $1-\alpha$ confidence interval is
$$\bar X-\bar Y \pm q \sqrt{\frac{S^2_1}{n_1}+\frac{S^2_2}{n_2} }$$

because of $q_{ \alpha} =1.96$, 95% t confidence interval for the mean difference in weight loss between the two groups (low carbohydrate versus low fat) is $$[0.9863,6.8137]$$


```{r}
diff_mean <- 5.8-1.9
conf <- sqrt(8.6^2/43+4.2^2/36)
(lower <- diff_mean - 1.96*conf)
(upper <- diff_mean + 1.96*conf)
```

#Q75

##a

```{r}
x <- read.csv('C://Users//AomoDa//Documents//Girls2004.csv')
library(ggplot2)
ggplot(data=x,aes(Smoker,Weight,fill=Smoker))+
  geom_boxplot()+
  labs(title=' boxplot of weights between
       nonsmokers and smokers')
ggplot(data=x,aes(Weight,fill=Smoker))+
  geom_density(alpha=0.3)+
  labs(title=' density of weights between
       nonsmokers and smokers')
```

##b

95% one-sided lower t confidence bound for the mean difference in weights between babies born to nonsmokers and smokers is $$[- \infty,558.8961]$$.

```{r}
no_smoker <- subset(x, select = Weight,
    subset = Smoker == "No", drop = T)
yes_smoker <- subset(x, select = Weight,
    subset = Smoker == "Yes", drop = T)
# use t test
t.test(no_smoker,yes_smoker,alternative = 'less')$conf
```

#Q76

- 95% confidence interval for the proportion of women who voted for Bush is $[43.73\%,49.98\%]$.
- 95% confidence interval for the proportion of men who voted for Bush is $[52.57\%,59.62\%]$.The intervals for the men and women does not  overlap and I think that the proportion of men who voted for Bush appears to be higher than women.
- 95% confidence interval for the difference in proportions is $[4.58\%,14.00\%]$.The proportion of men who voted for Bush is higher than women.

```{r}
#a
prop.test(459,980,correct = F,conf.level = 0.95)$conf
#b
prop.test(426,759,correct = F,conf.level = 0.95)$conf
#c
prop.test(c(426,459),c(759,980),
          correct = F,conf.level = 0.95)$conf
```

#77

we compare two differentways to judge whether the parameters $\theta_1$ and $\theta_2$ for two populations differ.We calculate estimates $\widehat{\theta_1}$ and $\widehat{\theta_2}$ and the corresponding standard errors $\widehat{SE_1}$ and $\widehat{SE_2}$

##a

$$\widehat {\theta_1} - 1.96 \widehat{SE_1} \leq \theta_1  \leq \widehat {\theta_1}  + 1.96 \widehat{SE_1} $$

$$\widehat {\theta_2} - 1.96 \widehat{SE_2} \leq \theta_2 \leq  \widehat {\theta_2} + 1.96 \widehat{SE_2} $$


**IF these confidence intervals overlap, we can obtain **,


when $(\widehat {\theta_1} + 1.96 \widehat {SE_1}) < (\widehat {\theta_2} + 1.96 \widehat {SE_2})$ ,there should have$$(\widehat {\theta_1} + 1.96 \widehat {SE_1})-(\widehat {\theta_2} - 1.96 \widehat {SE_2})  \geq 0$$

when $(\widehat {\theta_1} + 1.96 \widehat {SE_1}) > (\widehat {\theta_2} + 1.96 \widehat {SE_2})$, there should have$$(\widehat {\theta_1} - 1.96 \widehat {SE_1})-(\widehat {\theta_2} + 1.96 \widehat {SE_2})  \leq 0$$

Finally, we can always come to the same conclusion

$$(\widehat {\theta_1}-\widehat {\theta_2}) - 1.96 (\widehat {SE_1}+\widehat {SE_2}) \leq 0 $$
$$(\widehat {\theta_1}-\widehat {\theta_2}) + 1.96 (\widehat {SE_1}+\widehat {SE_2}) \geq 0$$


**IF these confidence intervals  do not overlap ** 

we can also compute that $(\widehat {\theta_1}-\widehat {\theta_2}) \pm 1.96 (\widehat {SE_1}+\widehat {SE_2})$ is all more than 0 or all less than 0, which  does not contain 0.

**Finally I can prove as follow**

The intervals given by Equations 7.21 and 7.22 overlap if and only if $(\widehat {\theta_1}-\widehat {\theta_2}) \pm 1.96 (\widehat {SE_1}+\widehat {SE_2})$ contains 0.



##b

###b.1
Because of standard errors $\widehat{SE_1} \geq 0$ and $\widehat{SE_2} \geq 0$ and we can obtain $$\frac{2\cdot \widehat{SE_1} \widehat{SE_2} }{\widehat{SE_1^2} +\widehat{SE_2^2}} \geq 0$$
finally we obtain
$$\frac{\widehat{SE_1} +\widehat{SE_2}}{\sqrt{\widehat{SE_1^2} +\widehat{SE_2^2}}}=\sqrt{\frac{ {(\widehat{SE_1} +\widehat{SE_2})}^2}{\widehat{SE_1^2} +\widehat{SE_2^2}}}=\sqrt{ 1+\frac{2\cdot \widehat{SE_1} \widehat{SE_2} }{\widehat{SE_1^2} +\widehat{SE_2^2}}  } \geq 1 $$


###b.2

As we know
$$\theta_1 \sim N(\widehat{\theta_1},\widehat{SE_1^2})$$
$$\theta_2 \sim N(\widehat{\theta_2},\widehat{SE_2^2})$$

and then obtain

$$\theta_1 - \theta_2 \sim N \left (\widehat{\theta_1}-\widehat{\theta_2}, \widehat{SE_1^2}+\widehat{SE_2^2} \right )$$

finally the ratio of the width of the interval is

$$(\widehat{\theta_1}-\widehat{\theta_2}) \pm 1.96 \cdot \sqrt{ \widehat{SE_1^2}+\widehat{SE_2^2}} $$


##c


If $(\widehat{\theta_1}-\widehat{\theta_2}) \pm 1.96 \cdot \sqrt{ \widehat{SE_1^2}+\widehat{SE_2^2}}$  contains 0,$\theta_1 = \theta_2$ ,otherwise $\theta_1 \neq \theta_2$.


#78

If a random sample with size $n$ is given and $u$ is unknown.
$$Y=\frac{(n-1) S^2}{ \sigma^2} \sim \chi^2 (n-1)$$ 
where
$$S^2=\frac{1}{n-1} \sum (X_i - {\bar X}^2) $$
so
$$P \left \{\  \frac{(n-1) S^2}{ \sigma^2} \leq \chi^2_\alpha(n-1) \  \right \}=1- \alpha$$
finally obtain the upper confidence intervals of $\sigma^2$ with $\alpha$ level is 
$$\left [\ \frac{(n-1)S^2}{\chi^2_\alpha (n-1)},+ \infty \  \right ]$$

write an R function that implements the formula.Finally I find that 90% upper confidence bound for $\sigma^2$ from the sample $x$ which comes from a normal distribution is $$[2.9255,+ \infty]$$ and $\sigma^2=5.0223$.

```{r}
var_upper_intervals <- function(x,alpha=0.9) {
 n <- length(x) #sample size
 s <- var(x) # the sample variance.
 q <- qchisq(alpha,df=n-1)  # 90% chisq value
 #90% upper confidence
 a <- (n-1) * s /q
 b <- Inf
 return(data.frame(var=s,a=a,b=b)) # results
}
# run my function
var_upper_intervals(x=c(0.556,7.267,1.939, 
                        1.907,2.124, 1.334, 
                        4.024, 0.455),
                    alpha=0.9)
```

#Q80

Use One Sample t-test

$$H_0:u = 98.6$$
$$H_1:u \neq 98.6$$

Report hypothesis test:

- $t = 2.745, df = 17, p-value = 0.01381 <0.05$,  we shoule reject $H_0$  and $u \neq 98.6$,95% confidence interval is $[98.64,98.92]$ which does not contain 98.6.

- Bootstrap confidence interval of the mean body temperature is $[98.65,98.90]$ ,which does not contain 98.6, the result is that  $u \neq 98.6$.

```{r}
#One Sample t-test
body <- c(98.0, 98.9 ,99.0, 98.9 ,
          98.8 ,98.6, 99.1 ,98.9 ,
          98.5,98.9, 98.9, 98.4, 
          99.0, 99.2 ,98.6, 98.8 ,
          98.9 ,98.7)
t.test(body,mu=98.6)
# bootstrap confidence interval
set.seed(80)
bt_mean_body <- replicate(10000,mean(
  sample(x = body,size = length(body),
         replace = T)))
# 95% confidence interval
quantile(bt_mean_body,
         c(0.025,0.975))

```

#Q81

##a

2-sample test for equality of proportions without continuity correction:

$$H_0:P(30\%  \ inspired  \ oxygen ) = P(80\% \ inspired  \ oxygen  )$$
$$H_1:P(30\% \ inspired  \ oxygen ) \neq P(80\% \ inspired  \ oxygen )$$

$X-squared = 5.978, df = 1, p-value = 0.01449 <0.05$, we should reject $H_0$ and $$H_1:P(30\% \ inspired  \ oxygen  ) \neq P(80\% \ inspired  \ oxygen  )$$. 95 percent confidence interval is $[0.0122,0.1078]$

```{r}
prop.test(c(28,13),c(250,250),correct = F)
```

##b


**这里没有写，不知道怎么说。。。。。。**
There was no control group— a group that received no inspired oxygen—inthis study. What is the implication of this?



#Q87

##a

$$H_0:P = 0.3$$
$$H_A:P < 0.3$$

$$\begin{array}{rcl}P(Type \ I \ error) &=&P(Reject \  H_0 \  | \  H_0  \ true)\\&=& P (  \sum^12_{i=1} X_i \leq 1 \ | \ X \sim Binom(1,0.3)  )\\&=& P (Y \leq 1 \ | \ Y \sim Binom(12,0.3)) \\&=& \sum_{i=0}^1  C_12^i  0.3^i(1-0.3)^{12-i} \\&=& 0.085     \end{array}$$


```{r}
pbinom(1,size = 12,prob = 0.3)
```

##b

If the alternative is true and success probability is $p$,where $p<0.3$.

$$\begin{array}{rcl} 1- \beta &=&P(Reject \  H_0 \  | \  H_A  \ true)\\&=& P  ( \sum_{i=1}^12 X_i \leq 1 \ | \ X \sim Binom(1,p) )\\&=& P (Y \leq 1 \ | \ Y \sim Binom(12,p)) \\&=& \sum_{i=0}^1  C_12^i  p^i(1-p)^{12-i}    \end{array}$$


##c

```{r}
# power function
power_fun <- function(p){
  return( (1-p)^12+12*p*(1-p)^11  )
}
# plot power against p
curve(power_fun,
      from = 0,
      to = 0.3,
      main = 'power against p',
      xlab='p',
      ylab='power')
```


